const axios = require('axios');

// System prompt for Thai grammar correction
const SYSTEM_PROMPT = `‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠ AI ‡∏ó‡∏µ‡πà‡∏ó‡∏≥‡∏´‡∏ô‡πâ‡∏≤‡∏ó‡∏µ‡πà‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÅ‡∏•‡∏∞‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡πÑ‡∏ß‡∏¢‡∏≤‡∏Å‡∏£‡∏ì‡πå‡∏Ç‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢‡πÇ‡∏î‡∏¢‡πÑ‡∏°‡πà‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÇ‡∏ó‡∏ô‡∏†‡∏≤‡∏©‡∏≤ ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏≠‡∏ö‡∏Å‡∏•‡∏±‡∏ö‡πÇ‡∏õ‡∏£‡∏î‡πÅ‡∏™‡∏î‡∏á‡∏ü‡∏¥‡∏•‡∏î‡πå 'corrected_text' ‡∏ó‡∏µ‡πà‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏Ñ‡∏≥‡∏ú‡∏¥‡∏î‡πÑ‡∏ß‡∏¢‡∏≤‡∏Å‡∏£‡∏ì‡πå‡πÉ‡∏´‡πâ‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á ‡πÅ‡∏•‡∏∞‡πÉ‡∏ô‡∏ü‡∏¥‡∏•‡∏î‡πå 'changes' ‡πÇ‡∏õ‡∏£‡∏î‡∏£‡∏∞‡∏ö‡∏∏‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏Ñ‡∏≥‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÅ‡∏õ‡∏•‡∏á‡∏à‡∏£‡∏¥‡∏á ‡πÜ ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô ‡∏´‡∏≤‡∏Å‡∏Ñ‡∏≥‡πÉ‡∏î‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÅ‡∏õ‡∏•‡∏á‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏™‡πà‡πÉ‡∏ô‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£ 'changes'`;

/**
 * LM Studio Service - Handles communication with LM Studio API
 */
class LMStudioService {
    constructor() {
        this.baseUrl = process.env.LM_STUDIO_BASE_URL || 'http://localhost:1234';
        this.model = process.env.LM_STUDIO_MODEL || 'google/gemma-3-12b';
        this.timeout = parseInt(process.env.LM_STUDIO_TIMEOUT) || 60000;
    }

    /**
     * Fix grammar of Thai text
     * @param {string} text - Text to correct
     * @returns {Promise<{corrected_text: string, changes: Array}>}
     */
    async fixGrammar(text) {
        const userMessage = `${text}`;

        const requestBody = {
            model: this.model,
            messages: [
                { role: 'system', content: SYSTEM_PROMPT },
                { role: 'user', content: userMessage }
            ],
            response_format: {
                type: 'json_schema',
                json_schema: {
                    name: 'grammar_fix_response',
                    strict: true,
                    schema: {
                        type: 'object',
                        properties: {
                            corrected_text: {
                                type: 'string',
                                description: '‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡πÉ‡∏´‡πâ‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡∏ï‡∏≤‡∏°‡∏´‡∏•‡∏±‡∏Å‡πÑ‡∏ß‡∏¢‡∏≤‡∏Å‡∏£‡∏ì‡πå'
                            },
                            changes: {
                                type: 'array',
                                items: {
                                    type: 'object',
                                    properties: {
                                        from: {
                                            type: 'string',
                                            description: '‡∏Ñ‡∏≥‡∏ï‡πâ‡∏ô‡∏â‡∏ö‡∏±‡∏ö'
                                        },
                                        to: {
                                            type: 'string',
                                            description: '‡∏Ñ‡∏≥‡∏ó‡∏µ‡πà‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡πÅ‡∏•‡πâ‡∏ß'
                                        }
                                    },
                                    required: ['from', 'to'],
                                    additionalProperties: false
                                },
                                description: '‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏Ç‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÅ‡∏õ‡∏•‡∏á‡∏Ñ‡∏≥‡∏ó‡∏∏‡∏Å‡∏Ñ‡∏≥‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÅ‡∏õ‡∏•‡∏á'
                            }
                        },
                        required: ['corrected_text', 'changes'],
                        additionalProperties: false
                    }
                }
            },
            temperature: 0.1,
            max_tokens: 10000000,
        };

        console.log('üì§ Sending request to LM Studio...');
        console.log('   Text:', text.substring(0, 50) + (text.length > 50 ? '...' : ''));

        try {
            const response = await axios.post(
                `${this.baseUrl}/v1/chat/completions`,
                requestBody,
                {
                    headers: { 'Content-Type': 'application/json' },
                    timeout: this.timeout
                }
            );

            const content = response.data.choices[0]?.message?.content;
            
            if (!content) {
                throw new Error('No response content from LM Studio');
            }

            console.log('üì• Raw response:', content);

            // Parse JSON response
            const result = JSON.parse(content);
            
            console.log('‚úÖ Parsed result:', result);
            
            return {
                corrected_text: result.corrected_text,
                changes: result.changes || []
            };

        } catch (error) {
            console.error('‚ùå LM Studio Error:', error.message);
            
            if (error.code === 'ECONNREFUSED') {
                throw new Error('‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡∏Å‡∏±‡∏ö LM Studio ‡πÑ‡∏î‡πâ ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤ LM Studio ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏≠‡∏¢‡∏π‡πà');
            }
            
            if (error.response) {
                throw new Error(`LM Studio error: ${error.response.status} - ${error.response.statusText}`);
            }
            
            throw error;
        }
    }
}

module.exports = new LMStudioService();
